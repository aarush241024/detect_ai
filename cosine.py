import streamlit as st
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch
import nltk
from nltk.util import ngrams
from nltk.lm.preprocessing import pad_sequence
from nltk.probability import FreqDist
import plotly.express as px
from collections import Counter
from nltk.corpus import stopwords
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Set page config at the very beginning
st.set_page_config(layout="wide", page_title="GPT Shield: AI Plagiarism Detector")

# Download required NLTK data
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)

# Load GPT-2 tokenizer and model
@st.cache_resource
def load_model():
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    model = GPT2LMHeadModel.from_pretrained('gpt2')
    return tokenizer, model

tokenizer, model = load_model()

# Sample corpus of human-written text (replace with a more comprehensive corpus)
human_corpus = [
    "The quick brown fox jumps over the lazy dog.",
    "To be or not to be, that is the question.",
    "I have a dream that one day this nation will rise up.",
    "Ask not what your country can do for you, ask what you can do for your country."
]

def calculate_perplexity(text):
    encoded_input = tokenizer.encode(text, add_special_tokens=False, return_tensors='pt')
    input_ids = encoded_input[0]
    
    with torch.no_grad():
        outputs = model(input_ids)
        logits = outputs.logits
    
    perplexity = torch.exp(torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), input_ids.view(-1)))
    return perplexity.item()

def calculate_burstiness(text):
    tokens = nltk.word_tokenize(text.lower())
    word_freq = FreqDist(tokens)
    repeated_count = sum(count > 1 for count in word_freq.values())
    burstiness_score = repeated_count / len(word_freq)
    return burstiness_score

def plot_top_repeated_words(text):
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token.lower() not in string.punctuation]
    
    word_counts = Counter(tokens)
    top_words = word_counts.most_common(10)
    
    words = [word for word, count in top_words]
    counts = [count for word, count in top_words]
    
    fig = px.bar(x=words, y=counts, labels={'x': 'Words', 'y': 'Counts'}, title='Top 10 Most Repeated Words')
    return fig

def calculate_cosine_similarity(text, corpus):
    vectorizer = TfidfVectorizer().fit_transform([text] + corpus)
    cosine_similarities = cosine_similarity(vectorizer[0:1], vectorizer[1:]).flatten()
    return max(cosine_similarities)

st.title("GPT Shield: AI Plagiarism Detector")
text_area = st.text_area("Enter text to analyze:", height=200)

if st.button("Analyze"):
    if text_area:
        col1, col2, col3 = st.columns([1,1,1])
        with col1:
            st.info("Your Input Text")
            st.success(text_area)
            
        with col2:
            st.info("Detection Scores")
            perplexity = calculate_perplexity(text_area)
            burstiness_score = calculate_burstiness(text_area)
            cosine_sim = calculate_cosine_similarity(text_area, human_corpus)
            
            st.metric("Perplexity", f"{perplexity:.2f}")
            st.metric("Burstiness Score", f"{burstiness_score:.2f}")
            st.metric("Cosine Similarity", f"{cosine_sim:.2f}")
            
            if perplexity > 30000 and burstiness_score < 0.2 and cosine_sim < 0.3:
                st.error("Text Analysis Result: Likely AI generated content")
            else:
                st.success("Text Analysis Result: Likely not generated by AI")
                
            st.warning("""
            Disclaimer: AI plagiarism detector apps can assist in identifying potential instances of plagiarism; 
            however, their results may not be entirely flawless or completely reliable. These tools employ advanced 
            algorithms, but they can still produce false positives or false negatives. It is recommended to use 
            AI plagiarism detectors as a supplementary tool alongside human judgment and manual verification 
            for accurate and comprehensive plagiarism detection.
            """)
                        
        with col3:
            st.info("Word Frequency Analysis")
            fig = plot_top_repeated_words(text_area)
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Please enter some text to analyze.")

st.markdown("---")
st.subheader("How to Interpret the Scores")
st.markdown("""
- **Perplexity**: A lower score indicates more predictable text, which might suggest AI generation. 
  Typical values for human-written text are often below 100, while AI-generated text can have much higher values.
- **Burstiness Score**: A higher score indicates more "bursty" patterns of word repetition, which is 
  often characteristic of human writing. Scores closer to 1 suggest more human-like patterns.
- **Cosine Similarity**: This score (0-1) measures how similar the input text is to our sample of 
  human-written text. Higher scores suggest more similarity to human writing.
""")

st.markdown("---")
st.info("""
This tool uses a combination of perplexity calculation, burstiness analysis, and cosine similarity 
to estimate the likelihood of text being AI-generated or human-written. While it provides useful 
insights, it should not be considered definitive. Always use critical thinking and multiple sources 
of verification when assessing the origin of a text.
""")